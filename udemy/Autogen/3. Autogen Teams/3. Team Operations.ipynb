{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21ef384",
   "metadata": {},
   "source": [
    "# Team Operations : Reset, Stop, Resume and Abort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16711ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4o', api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42836555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "add_1_agent_first = AssistantAgent(\n",
    "    name = 'add_1_agent_first',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Add 1 to the number, first number is 0. Give result as output\"\n",
    ")\n",
    "\n",
    "add_1_agent_second = AssistantAgent(\n",
    "    name = 'add_1_agent_second',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Add 1 to the number. Give result as output.\"\n",
    ")\n",
    " \n",
    "add_1_agent_third = AssistantAgent(\n",
    "    name = 'add_1_agent_third',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Add 1 to the number. Give result as output.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1296ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    [add_1_agent_first, add_1_agent_second, add_1_agent_third],\n",
    "    max_turns=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f818a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- add_1_agent_first ----------\n",
      "The initial number is 0. Adding 1 to it gives a result of 1.\n",
      "---------- add_1_agent_second ----------\n",
      "The initial number is 1. Adding 1 to it gives a result of 2.\n",
      "---------- add_1_agent_third ----------\n",
      "The result of adding 1 to the number 1 is 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=24, completion_tokens=20), metadata={}, content='The initial number is 0. Adding 1 to it gives a result of 1.', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=47, completion_tokens=20), metadata={}, content='The initial number is 1. Adding 1 to it gives a result of 2.', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=75, completion_tokens=16), metadata={}, content='The result of adding 1 to the number 1 is 2.', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "await Console(team.run_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aff54e",
   "metadata": {},
   "source": [
    "# Resuming a Team\n",
    "Teams are stateful and maintains the conversation history and context after each run, unless you reset the team.\n",
    "\n",
    "\n",
    "We can resume a team to continue from where it left off by calling the run() or run_stream() method without a **new task**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aac3f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- add_1_agent_first ----------\n",
      "4\n",
      "---------- add_1_agent_second ----------\n",
      "5\n",
      "---------- add_1_agent_third ----------\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=55, completion_tokens=2), metadata={}, content='4', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=60, completion_tokens=2), metadata={}, content='5', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=70, completion_tokens=2), metadata={}, content='6', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b05f239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- add_1_agent_first ----------\n",
      "7\n",
      "---------- add_1_agent_second ----------\n",
      "8\n",
      "---------- add_1_agent_third ----------\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=86, completion_tokens=2), metadata={}, content='7', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=91, completion_tokens=2), metadata={}, content='8', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=101, completion_tokens=2), metadata={}, content='9', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83452498",
   "metadata": {},
   "source": [
    "# team resumed from where it left off in the output above, and the first message is from the next agent after the last agent that spoke before the team stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de6684b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "What was the largest number you got in the result?\n",
      "---------- add_1_agent_first ----------\n",
      "The largest number I provided in the result was 9.\n",
      "---------- add_1_agent_second ----------\n",
      "The largest number I provided in the result was 10.\n",
      "---------- add_1_agent_third ----------\n",
      "The largest number provided in the result was 9.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='What was the largest number you got in the result?', type='TextMessage'), TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=133, completion_tokens=13), metadata={}, content='The largest number I provided in the result was 9.', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=149, completion_tokens=13), metadata={}, content='The largest number I provided in the result was 10.', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=170, completion_tokens=12), metadata={}, content='The largest number provided in the result was 9.', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream(task = 'What was the largest number you got in the result?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b0fa5",
   "metadata": {},
   "source": [
    "# Reset our Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18c91371",
   "metadata": {},
   "outputs": [],
   "source": [
    "await team.reset() # on_reset() on all agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7546e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- add_1_agent_first ----------\n",
      "1\n",
      "---------- add_1_agent_second ----------\n",
      "2\n",
      "---------- add_1_agent_third ----------\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=24, completion_tokens=2), metadata={}, content='1', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=29, completion_tokens=2), metadata={}, content='2', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=39, completion_tokens=2), metadata={}, content='3', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b8893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02178c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9368a00b",
   "metadata": {},
   "source": [
    "## Covered in Future Videos in the Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c44dc",
   "metadata": {},
   "source": [
    "# Aborting a Team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc98cf3c",
   "metadata": {},
   "source": [
    "Different from stopping a team, aborting a team will immediately stop the team and raise a CancelledError exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea3283",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "catching classes that do not inherit from BaseException is not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m run\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Agentic-AI/Autogen/autogen-env/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py:117\u001b[39m, in \u001b[36mConsole\u001b[39m\u001b[34m(stream, no_inline_images, output_stats, user_input_manager)\u001b[39m\n\u001b[32m    115\u001b[39m streaming_chunks: List[\u001b[38;5;28mstr\u001b[39m] = []\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TaskResult):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Agentic-AI/Autogen/autogen-env/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py:408\u001b[39m, in \u001b[36mBaseGroupChat.run_stream\u001b[39m\u001b[34m(self, task, cancellation_token)\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_running:\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe team is already running, it cannot run again until it is stopped.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    409\u001b[39m \u001b[38;5;28mself\u001b[39m._is_running = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: The team is already running, it cannot run again until it is stopped.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m run\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio.CancelledError():\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTask Was Cancelled\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: catching classes that do not inherit from BaseException is not allowed"
     ]
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "run2 = asyncio.create_task(\n",
    "    Console(team.run_stream(task = 'Give a short Story about a lion atmost 40 words',cancellation_token=cancellation_token))\n",
    ")\n",
    "\n",
    "await asyncio.sleep(2)\n",
    "cancellation_token.cancel()\n",
    "\n",
    "try:\n",
    "    result = await run2\n",
    "except asyncio.CancelledError():\n",
    "    print(\"Task Was Cancelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458456b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
