{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7bd7da7",
   "metadata": {},
   "source": [
    "# Memory in Autogen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd79c8",
   "metadata": {},
   "source": [
    "## How much is the fever - Fahrenheit\n",
    "## What's the temperature in Celsius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d11b6b",
   "metadata": {},
   "source": [
    "AgentChat provides a [`Memory`](https://microsoft.github.io/autogen/stable//reference/python/autogen_core.memory.html#autogen_core.memory.Memory \"autogen_core.memory.Memory\") protocol that can be extended to provide this functionality. The key methods are `query`, `update_context`, `add`, `clear`, and `close`.\n",
    "\n",
    "-   `add`: add new entries to the memory store\n",
    "\n",
    "-   `query`: retrieve relevant information from the memory store\n",
    "\n",
    "-   `update_context`: mutate an agent's internal `model_context` by adding the retrieved information (used in the [`AssistantAgent`](https://microsoft.github.io/autogen/stable//reference/python/autogen_agentchat.agents.html#autogen_agentchat.agents.AssistantAgent \"autogen_agentchat.agents.AssistantAgent\") class)\n",
    "\n",
    "-   `clear`: clear all entries from the memory store\n",
    "\n",
    "-   `close`: clean up any resources used by the memory store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbdbcd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "gemini_api_key = os.getenv('GOOGLE_GEMINI_API_KEY')\n",
    "\n",
    "# Model client\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4o', api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c277ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "from autogen_core.memory import ListMemory,MemoryContent,MemoryMimeType\n",
    "\n",
    "\n",
    "# Create a memory for the agent\n",
    "user_memory = ListMemory()\n",
    "\n",
    "await user_memory.add(MemoryContent(content='Weather should be in metric units',mime_type=MemoryMimeType.TEXT))\n",
    "await user_memory.add(MemoryContent(content=\"Meal recipe should be vegan\",mime_type=MemoryMimeType.TEXT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967a6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_weather(city: str, units: str = \"imperial\") -> str:\n",
    "    if units == \"imperial\":\n",
    "        return f\"The weather in {city} is 73 °F and Sunny.\"\n",
    "    elif units == \"metric\":\n",
    "        return f\"The weather in {city} is 23 °C and Sunny.\"\n",
    "    else:\n",
    "        return f\"Sorry, I don't know the weather in {city}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14fb82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_agent = AssistantAgent(\n",
    "    name = 'Assistant_agent',\n",
    "    model_client=model_client,\n",
    "    memory = [user_memory],\n",
    "    tools= [get_weather],\n",
    "    system_message=\"\"\"You are a helpful assistant. You can answer questions about the and also use tools wherenver neccessary.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aefeaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the weather in New York?\n",
      "---------- MemoryQueryEvent (Assistant_agent) ----------\n",
      "[MemoryContent(content='Weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe should be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)]\n",
      "---------- ToolCallRequestEvent (Assistant_agent) ----------\n",
      "[FunctionCall(id='call_t5sPwv0cphJJ890SBLj4l28V', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')]\n",
      "---------- ToolCallExecutionEvent (Assistant_agent) ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_t5sPwv0cphJJ890SBLj4l28V', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (Assistant_agent) ----------\n",
      "The weather in New York is 23 °C and Sunny.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='What is the weather in New York?', type='TextMessage'), MemoryQueryEvent(source='Assistant_agent', models_usage=None, metadata={}, content=[MemoryContent(content='Weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe should be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)], type='MemoryQueryEvent'), ToolCallRequestEvent(source='Assistant_agent', models_usage=RequestUsage(prompt_tokens=121, completion_tokens=19), metadata={}, content=[FunctionCall(id='call_t5sPwv0cphJJ890SBLj4l28V', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='Assistant_agent', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_t5sPwv0cphJJ890SBLj4l28V', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='Assistant_agent', models_usage=None, metadata={}, content='The weather in New York is 23 °C and Sunny.', type='ToolCallSummaryMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = assistant_agent.run_stream(task = \"What is the weather in New York?\")\n",
    "await(Console(stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7de8c7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserMessage(content='What is the weather in New York?', source='user', type='UserMessage'),\n",
       " SystemMessage(content='\\nRelevant memory content (in chronological order):\\n1. Weather should be in metric units\\n2. Meal recipe should be vegan\\n', type='SystemMessage'),\n",
       " AssistantMessage(content=[FunctionCall(id='call_t5sPwv0cphJJ890SBLj4l28V', arguments='{\"city\":\"New York\",\"units\":\"metric\"}', name='get_weather')], thought=None, source='Assistant_agent', type='AssistantMessage'),\n",
       " FunctionExecutionResultMessage(content=[FunctionExecutionResult(content='The weather in New York is 23 °C and Sunny.', name='get_weather', call_id='call_t5sPwv0cphJJ890SBLj4l28V', is_error=False)], type='FunctionExecutionResultMessage')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await assistant_agent.model_context.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6af287ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Can you give me a soup recipe ?\n",
      "---------- MemoryQueryEvent (Assistant_agent) ----------\n",
      "[MemoryContent(content='Weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe should be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)]\n",
      "---------- TextMessage (Assistant_agent) ----------\n",
      "Here's a delicious vegan soup recipe for you:\n",
      "\n",
      "**Vegan Lentil Soup**\n",
      "\n",
      "**Ingredients:**\n",
      "- 1 tablespoon olive oil\n",
      "- 1 onion, chopped\n",
      "- 2 carrots, diced\n",
      "- 2 celery stalks, diced\n",
      "- 3 cloves garlic, minced\n",
      "- 1 teaspoon ground cumin\n",
      "- 1 teaspoon ground coriander\n",
      "- 1 teaspoon smoked paprika\n",
      "- 1 cup dried lentils, rinsed\n",
      "- 1 can (14-ounce) diced tomatoes\n",
      "- 4 cups vegetable broth\n",
      "- 2 cups water\n",
      "- Salt and pepper to taste\n",
      "- 2 cups kale or spinach, chopped\n",
      "- 1 tablespoon lemon juice\n",
      "\n",
      "**Instructions:**\n",
      "1. In a large pot, heat olive oil over medium heat. Add onions, carrots, and celery. Sauté until onions are translucent.\n",
      "2. Stir in garlic, cumin, coriander, and smoked paprika. Cook for about 1 minute until fragrant.\n",
      "3. Add lentils, diced tomatoes, vegetable broth, and water. Bring to a boil.\n",
      "4. Reduce heat and let it simmer for 25-30 minutes or until lentils are tender.\n",
      "5. Season with salt and pepper.\n",
      "6. Stir in kale or spinach and lemon juice. Cook for an additional 5 minutes.\n",
      "7. Serve hot and enjoy your healthy vegan soup! \n",
      "\n",
      "Feel free to customize it with your favorite vegetables or spices. Enjoy cooking!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Can you give me a soup recipe ?', type='TextMessage'), MemoryQueryEvent(source='Assistant_agent', models_usage=None, metadata={}, content=[MemoryContent(content='Weather should be in metric units', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None), MemoryContent(content='Meal recipe should be vegan', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)], type='MemoryQueryEvent'), TextMessage(source='Assistant_agent', models_usage=RequestUsage(prompt_tokens=204, completion_tokens=290), metadata={}, content=\"Here's a delicious vegan soup recipe for you:\\n\\n**Vegan Lentil Soup**\\n\\n**Ingredients:**\\n- 1 tablespoon olive oil\\n- 1 onion, chopped\\n- 2 carrots, diced\\n- 2 celery stalks, diced\\n- 3 cloves garlic, minced\\n- 1 teaspoon ground cumin\\n- 1 teaspoon ground coriander\\n- 1 teaspoon smoked paprika\\n- 1 cup dried lentils, rinsed\\n- 1 can (14-ounce) diced tomatoes\\n- 4 cups vegetable broth\\n- 2 cups water\\n- Salt and pepper to taste\\n- 2 cups kale or spinach, chopped\\n- 1 tablespoon lemon juice\\n\\n**Instructions:**\\n1. In a large pot, heat olive oil over medium heat. Add onions, carrots, and celery. Sauté until onions are translucent.\\n2. Stir in garlic, cumin, coriander, and smoked paprika. Cook for about 1 minute until fragrant.\\n3. Add lentils, diced tomatoes, vegetable broth, and water. Bring to a boil.\\n4. Reduce heat and let it simmer for 25-30 minutes or until lentils are tender.\\n5. Season with salt and pepper.\\n6. Stir in kale or spinach and lemon juice. Cook for an additional 5 minutes.\\n7. Serve hot and enjoy your healthy vegan soup! \\n\\nFeel free to customize it with your favorite vegetables or spices. Enjoy cooking!\", type='TextMessage')], stop_reason=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = assistant_agent.run_stream(task = \"Can you give me a soup recipe ?\")\n",
    "await(Console(stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dccc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
